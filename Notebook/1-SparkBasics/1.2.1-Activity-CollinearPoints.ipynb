{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collinear Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Collinear points\n",
    "\n",
    "Definition of collinearity[1]: In geometry, collinearity of a set of points is the property of their lying on a single line. A set of points with this property is said to be collinear.\n",
    "\n",
    "![](non-collinear-points.jpg)\n",
    "\n",
    "Here, points P,Q,R and A,R,B are collinear. However, points A,B,C are non-collinear. For more, refer [2].\n",
    "\n",
    "1. https://en.wikipedia.org/wiki/Collinearity\n",
    "2. http://www.mathcaptain.com/geometry/collinear-points.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterizing lines\n",
    "In order to determine whether a set of points all lie on the same line we need a standard way to define (or parametrize) a line.\n",
    "\n",
    "* One way of defining a line is as the set of points $(x,y)$ such that $y=ax+b$ for some fixed real values $a,b$.\n",
    "* We call $a$ the **slope** of the line and $b$ is the $y$-intercept which is defined as the value of $y$ when $x=0$.\n",
    "* This parameterization works for *almost* all lines. It does not work for vertical lines. For those lines we define $a$ to be **infinity** and $b$ to be the $x$ intercept of the line (the line is parallel to the $y$ axis so it does not intercept the $y$ axis (other than if it is the vertical line going through the origin).\n",
    "\n",
    "To summarize, given two different points $(x_1,y_1) \\neq (x_2,y_2)$, we define the parameterization $(a,b)$ as:\n",
    "* **if $x_1=x_2$: ** $(\\mbox{Inf},x_1)$ \n",
    "* **Else:** $(a,b)$ such that $y_1=a x_1 +b$ and $y_2=a x_2 +b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Given an input file with an arbitrary set of co-ordinates, your task is to use pyspark library functions and write a program in python3 to find if three or more points are collinear.\n",
    "\n",
    "For instance, if given these points: `{(1,1), (0,1), (2,2), (3,3), (0,5), (3,4), (5,6), (0,-3), (-2,-2)}`\n",
    "\n",
    "Sets of collinear points are: `{((-2,-2), (1,1), (2,2), (3,3)), ((0,1), (3,4), (5,6)), ((0,-3), (0,1), (0,5))}`. Note that the ordering of the points in a set or the order of the sets does not matter. \n",
    "\n",
    "Note: \n",
    "* Every set of collinear points has to have **at least three points** (any pair of points lie on a line).\n",
    "* There are two types of test cases:\n",
    "     * **Visible Test cases**: Test cases given to you as a part of the notebook. These tests will help you validate your program and figure out bugs in it if any.\n",
    "     * **Hidden Test cases**: Test cases that are not given as a part of the notebook, but will be used for grading. Cells in this notebook that have `//Hidden test cases here` are read-only cells containing hidden tests.\n",
    "     * Any cell that does not require you to submit code cannot be modified. For example: Assert statement unit test cells. Cells that have `# YOUR CODE HERE` are the ONLY ones you will need to alter. \n",
    "     * DO NOT change the names of functions. \n",
    "     * Remove the `Raise NotImplementedError()` line when you write the definition of your function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the Approach\n",
    "\n",
    "The goal of this assignment is to make you familiar with programming using pyspark. There are many ways to find sets of collinear points from a list of points. For the purposes of this assignment, we shall stick with the below approach:\n",
    "\n",
    "1. List all pairs of points. You can do that efficiently in spark by computing cartesian product of the list of points with itself. For example, given three points $[(1,0), (2,0), (3,0)]$, we construct a list of nine pairs  \n",
    "$[((1,0),(1,0)),((1,0), (2,0)),((1,0),(3,0))$  \n",
    "$((2,0),(1,0)),((2,0), (2,0)),((2,0),(3,0))$  \n",
    "$((3,0),(1,0)),((3,0), (2,0)),((3,0),(3,0))]$  \n",
    "\n",
    "2. Remove the pairs in which the same point appears twice such as $((2,0),(2,0))$. After these elimination you end up (for this example) with a list of just six pairs:  \n",
    "$[((1,0),(2,0)),((1,0),(3,0)),((2,0),(1,0)),((2,0),(3,0)),((3,0),(1,0)),((3,0),(2,0))]$\n",
    "\n",
    "2. For each pair of points, find the parameterization $(a,b)$ of the line connecting them as described above.\n",
    "\n",
    "3. Group the pairs according to their parameters. Clearly, if two pairs have the same $(a,b)$ values, all points in the two pairs lie on the same line.\n",
    "\n",
    "3. Eliminate the groups that contain only one pair (any pair of points defines a line).\n",
    "4. In each of the remaining groups, unpack the point-pairs to identify the individual points.\n",
    "Note that if a set of points $(x_1,y_1),\\ldots,(x_k,y_k)$ lie on the same line then each point will appear $k-1$ times in the list of point-pairs. You therefore need to transform the list of points into sets to remove duplicates.\n",
    "\n",
    "5. Output the sets of 3 or more colinear points.\n",
    "\n",
    "Your task is to implement the described algorithm in Spark. You should use RDD's all the way through and collect the results into the driver only at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@1bf55aa3\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "Here are some helper functions that you are encouraged to use in your implementations. Do not change these functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `format_result` takes an element of the form shown below in the example. It outputs a tuple of all points that are collinear (shown below).\n",
    "\n",
    "Input: ((A,slope), [C1,..., Ck]) where each of A, C1, ..., Ck is a point of form (Ax, Ay) and slope is of type float.\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Code</font>**\n",
    "``` python\n",
    "my_input = (((2, 1), 0.5), [(4, 2), (6, 3)]) \n",
    "format_result(my_input)\n",
    "```\n",
    "Output: (C1,..., Ck, A) each of A,C1,...,Ck is a point of form (Ax, Ay)\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "((4, 2), (6, 3), (2, 1))\n",
    "```\n",
    "\n",
    "<font color=\"red\">**Hint : **</font> The above example is given just to provide the input and output format. This function is called a different way in the spark exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined type alias MyTuple\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Define a new type\n",
    "type MyTuple = (((AnyVal, AnyVal), AnyVal), List[(AnyVal,AnyVal)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_result: (x: MyTuple)List[(AnyVal, AnyVal)]\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_result(x:MyTuple) = {\n",
    "    val s = x._2\n",
    "    s :+ (x._1)._1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_input: MyTuple = (((2,1),0.5),List((4,2), (6,3)))\r\n",
       "res23: List[(AnyVal, AnyVal)] = List((4,2), (6,3), (2,1))\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val my_input: MyTuple= (((2,1),0.5),List((4,2), (6,3)))\n",
    "format_result(my_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: `to_tuple`\n",
    "\n",
    "The function `to_tuple` converts each point of form 'Ax Ay' into a point of form (Ax, Ay) for further processing.\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Code</font>**\n",
    "``` scala\n",
    "my_input = '2 3'\n",
    "to_tuple(my_input)\n",
    "```\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` scala\n",
    "(2, 3)\n",
    "```\n",
    "\n",
    "<font color=\"red\">**Hint : **</font> The above example is given just to provide the input and output format. This function is called a different way in the spark exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s: String = 2 3\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s:String = \"2 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s2: Array[String] = Array(2, 3)\r\n",
       "res25: (Int, Int) = (2,3)\n"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s2 = s.split(\" \")\n",
    "(s2(0).toInt, s2(1).toInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to_tuple: (s: String)(Int, Int)\n"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_tuple(s: String) = {\n",
    "    val s2 = s.split(\" \")\n",
    "    (s2(0).toInt, s2(1).toInt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(to_tuple(\"1 1\") == (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: `non_duplicates`\n",
    "\n",
    "The function `non_duplicates` checks if a set of points contains duplicates or not.\n",
    "\n",
    "Input: Pair (A,B) where A and B are of form (Ax, Ay) and (Bx, By) respectively.\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Code</font>**\n",
    "``` python\n",
    "my_input = ((0,0),(1,2))\n",
    "non_duplicates(my_input)\n",
    "```\n",
    "\n",
    "Output: Returns True if A != B, False otherwise.\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "True\n",
    "```\n",
    "\n",
    "<font color=\"red\">**Hint : **</font> The above example is given just to provide the input and output format. This function is called a different way in the spark exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a: (Int, Int) = (0,0)\r\n",
       "b: (Int, Int) = (1,2)\r\n",
       "res28: Boolean = true\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val a = (0,0)\n",
    "val b = (1,2)\n",
    "\n",
    "a!=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non_duplicates: (x: ((AnyVal, AnyVal), (AnyVal, AnyVal)))Boolean\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def non_duplicates(x: ((AnyVal,AnyVal), (AnyVal, AnyVal))): Boolean ={\n",
    "    val a = x._1\n",
    "    val b = x._2\n",
    "    a != b\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(non_duplicates((0,0),(1,2))== true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(non_duplicates((0,0),(1,2)).isInstanceOf[Boolean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(non_duplicates((0,0),(0,0))==false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
